{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the `MiniBach` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: From music data to one-hot-encoded arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we take the pre-processed chunks of 4-measure-long chorales and encode them into the input representation of the neural network.\n",
    "\n",
    "Originally, the chunks specify whether there is a note, *hold* (encoded as `--`), or rest symbol at any given sixteenth note. When the event is a note, the pitch and octave (e.g., `C4`) are specified.\n",
    "\n",
    "We turn those events into numbers that will be eventually **one-hot-encoded** in the final input vector representation.\n",
    "\n",
    "The one-hot-encoded vectors of the input (soprano voice) and output (alto, tenor, and bass) are stored as the `numpy` arrays `input.npy` and `output.npy`, by the end of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the `dataset.csv` generated in the first part of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4-measure chunks are named in the following way:\n",
    "\n",
    "`<name_of_the_choral>_chunk_<number_of_chunk>`\n",
    "\n",
    "For example, `chor_002.krn_chunk_0`\n",
    "\n",
    "This name is encoded in the column `file` of the dataset. Therefore, we can iterate over each `chunk` in the dataset and encode its `soprano` as `x` and `(alto, tenor, bass)` as `y` values for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = list(sorted(set(df.file.to_list())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MiniBach` architecture considers a different range of notes for each part. The actual range is not specified in the book but the number of notes that belong to the range of a given part are specified:\n",
    "\n",
    "\n",
    "| Part   |  range  |\n",
    "|--------|---------|\n",
    "|Soprano | 20 notes|\n",
    "|Alto:   | 20 notes|\n",
    "|Tenor:  | 20 notes|\n",
    "|Bass:   | 27 notes|\n",
    "\n",
    "Nevertheless, trying to provide a collection of note ranges that satisfy the constraint and work for all Bach chorales with a 4/4 time signature, in my experience, resulted to be impossible.\n",
    "\n",
    "A possible explanation for this is that the book used a smaller set of chorales (it doesn't mention how many chorales were used for training).\n",
    "\n",
    "The minimum ranges I could come up with, that are able to work for all Bach chorales, are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the soprano has a range of 25 notes (plus the \"hold\" symbol)\n",
      "the alto has a range of 23 notes (plus the \"hold\" symbol)\n",
      "the tenor has a range of 22 notes (plus the \"hold\" symbol)\n",
      "the bass has a range of 29 notes (plus the \"hold\" symbol)\n"
     ]
    }
   ],
   "source": [
    "SOPRANO_MIN = 57\n",
    "SOPRANO_MAX = 81\n",
    "\n",
    "ALTO_MIN = 52\n",
    "ALTO_MAX = 74\n",
    "\n",
    "TENOR_MIN = 48\n",
    "TENOR_MAX = 69\n",
    "\n",
    "BASS_MIN = 36\n",
    "BASS_MAX = 64\n",
    "\n",
    "ranges = {\n",
    "    'soprano': {midinumber: (midinumber - SOPRANO_MIN + 1) for midinumber in range(SOPRANO_MIN, SOPRANO_MAX + 1)},\n",
    "    'alto': {midinumber: (midinumber - ALTO_MIN + 1) for midinumber in range(ALTO_MIN, ALTO_MAX + 1)},\n",
    "    'tenor': {midinumber: (midinumber - TENOR_MIN + 1) for midinumber in range(TENOR_MIN, TENOR_MAX + 1)},\n",
    "    'bass': {midinumber: (midinumber - BASS_MIN + 1) for midinumber in range(BASS_MIN, BASS_MAX + 1)},\n",
    "}\n",
    "\n",
    "for part, notes in ranges.items():\n",
    "    print(f'the {part} has a range of {len(notes)} notes (plus the \"hold\" symbol)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these ranges has of course implications for the neural network, as the number of input and output parameters will be bigger. For this experiment, I decided to make a compromise and use a more complex network in order to use all the training examples. \n",
    "\n",
    "> Alternatively, you can also try to adjust the voice ranges to the sizes described in `MiniBach` in order to have a smaller network. For example, you can ignore outlier examples that exceed the ranges.\n",
    "\n",
    "The ranges used in this implementation are the following:\n",
    "\n",
    "| Part   |       Range         |\n",
    "|--------|---------------------|\n",
    "|Soprano | A3 to A5 (25 notes) |\n",
    "|Alto:   | E3 to D5 (23 notes) |\n",
    "|Tenor:  | C3 to A4 (22 notes) |\n",
    "|Bass:   | C2 to E4 (29 notes) |\n",
    "\n",
    "The size of the input vector is therefore \n",
    "\n",
    "$$\n",
    "(25 + 1) (16) (4) = 1664\n",
    "$$\n",
    "\n",
    "The size of the output vector is \n",
    "\n",
    "$$\n",
    "((23 + 1) + (22 + 1) + (29 + 1))  (16) (4) = 4928\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function `encode_note` translates the notes and symbols in the dataset to the corresponding numbers we will use in our one-hot encoding. Rests are ignored (as in the description of the book), and `hold` symbols have a special index `0` in the input vector of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_note(n, rang):\n",
    "    if n == '--' or n == 'Rest':\n",
    "        ret = 0\n",
    "    else:\n",
    "        note = music21.note.Note(n)\n",
    "        ret = ranges[rang][note.pitch.midi]\n",
    "    return ret\n",
    "\n",
    "def one_hot_encode(idx, rang):\n",
    "    length = len(ranges[rang].values())\n",
    "    ret = [0] * (length + 1)\n",
    "    ret[idx] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for chunk in chunks:\n",
    "    dfchunk = df[df.file == chunk]    \n",
    "    s = dfchunk.soprano.apply(encode_note, args=('soprano',)) \n",
    "    xi = np.array([[one_hot_encode(idx, 'soprano') for idx in s]])    \n",
    "    xi = xi.reshape(-1)    \n",
    "    a = dfchunk.alto.apply(encode_note, args=('alto',))\n",
    "    t = dfchunk.tenor.apply(encode_note, args=('tenor',))\n",
    "    b = dfchunk.bass.apply(encode_note, args=('bass',))    \n",
    "    ya = np.array([one_hot_encode(idx, 'alto') for idx in a])\n",
    "    yt = np.array([one_hot_encode(idx, 'tenor') for idx in t])\n",
    "    yb = np.array([one_hot_encode(idx, 'bass') for idx in b])  \n",
    "    yi = np.concatenate((ya, yt, yb), axis=None)        \n",
    "    x.append(xi)\n",
    "    y.append(yi)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('input.npy', x)\n",
    "np.save('output.npy', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written the given (soprano) and accompanying (alto, tenor, and bass) melodies as one-hot encoded vectors. \n",
    "\n",
    "These vectors can be easily applied as training data for the neural network. \n",
    "\n",
    "At this point, the values of those one-hot encoded representations are barely recognizable as music information. They are mostly large arrays of 1s and 0s.\n",
    "\n",
    "In the next part, we use them to train the MiniBach network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit3096ab794bfa49e88dd2c11f522e534a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
